{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT Jokes",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isamu-isozaki/toxic-joke-generator/blob/master/GPT_Jokes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giaI3YfNz5o8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_folder_name = \"model\"\n",
        "past_folder_name = \"past\"\n",
        "#Makde the folder's of these names in google drive. The current model will be saved to model_folder_name and past models \n",
        "#including the current model will be saved to past_folder_name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu95ko3QAJKO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "04a55fd8-eda9-4013-9fc1-9aa8d1d4d02b"
      },
      "source": [
        "#cd .."
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fIjh_Qv74SL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!rm -rf toxic-joke-generator\n",
        "#Used to delete toxic-joke-generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE_fFgQ8a_Dd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Thanks https://www.reddit.com/r/MachineLearning/comments/bgvzdu/d_jokes_generated_via_gpt2/\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG_g6efA_ZNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r04wALg1_ede",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGXuWReP_hz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ListFolder(parent, show=False):\n",
        "  filelist=[]\n",
        "  file_list = drive.ListFile({'q': \"'%s' in parents and trashed=false\" % parent}).GetList()\n",
        "  for f in file_list:\n",
        "    if show:\n",
        "      print(f\"{f['title']}, {f['id']}\")\n",
        "    if f['mimeType']=='application/vnd.google-apps.folder': # if folder\n",
        "        if f['title'] == model_folder_name or f['title'] == past_folder_name:          \n",
        "          filelist.append({\"id\":f['id'],\"title\":f['title'], \"mimeType\": 'application/vnd.google-apps.folder', \"list\":ListFolder(f['id'])})\n",
        "        else:\n",
        "          for f1 in ListFolder(f['id']):\n",
        "            filelist.append(f1)\n",
        "    else:\n",
        "        filelist.append({\"id\":f['id'],\"title\":f['title'],\"mimeType\":\"file\",\"title1\":f['alternateLink']})\n",
        "  return filelist\n",
        "fl = ListFolder('root')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdi8bFXn9jB_",
        "colab_type": "code",
        "outputId": "a39a38e6-1c16-4a4a-fe01-f8ae287545ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "!git clone https://github.com/isamu-isozaki/toxic-joke-generator.git"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'toxic-joke-generator'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Counting objects:   3% (1/30)   \u001b[K\rremote: Counting objects:   6% (2/30)   \u001b[K\rremote: Counting objects:  10% (3/30)   \u001b[K\rremote: Counting objects:  13% (4/30)   \u001b[K\rremote: Counting objects:  16% (5/30)   \u001b[K\rremote: Counting objects:  20% (6/30)   \u001b[K\rremote: Counting objects:  23% (7/30)   \u001b[K\rremote: Counting objects:  26% (8/30)   \u001b[K\rremote: Counting objects:  30% (9/30)   \u001b[K\rremote: Counting objects:  33% (10/30)   \u001b[K\rremote: Counting objects:  36% (11/30)   \u001b[K\rremote: Counting objects:  40% (12/30)   \u001b[K\rremote: Counting objects:  43% (13/30)   \u001b[K\rremote: Counting objects:  46% (14/30)   \u001b[K\rremote: Counting objects:  50% (15/30)   \u001b[K\rremote: Counting objects:  53% (16/30)   \u001b[K\rremote: Counting objects:  56% (17/30)   \u001b[K\rremote: Counting objects:  60% (18/30)   \u001b[K\rremote: Counting objects:  63% (19/30)   \u001b[K\rremote: Counting objects:  66% (20/30)   \u001b[K\rremote: Counting objects:  70% (21/30)   \u001b[K\rremote: Counting objects:  73% (22/30)   \u001b[K\rremote: Counting objects:  76% (23/30)   \u001b[K\rremote: Counting objects:  80% (24/30)   \u001b[K\rremote: Counting objects:  83% (25/30)   \u001b[K\rremote: Counting objects:  86% (26/30)   \u001b[K\rremote: Counting objects:  90% (27/30)   \u001b[K\rremote: Counting objects:  93% (28/30)   \u001b[K\rremote: Counting objects:  96% (29/30)   \u001b[K\rremote: Counting objects: 100% (30/30)   \u001b[K\rremote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 127 (delta 15), reused 16 (delta 7), pack-reused 97\u001b[K\n",
            "Receiving objects: 100% (127/127), 211.18 MiB | 36.49 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n",
            "Checking out files: 100% (47/47), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju7uo6bJ91It",
        "colab_type": "code",
        "outputId": "3e1f61a1-6aca-4157-c415-2bae3541fd63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd toxic-joke-generator"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/toxic-joke-generator\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRVX5nn397LA",
        "colab_type": "code",
        "outputId": "fbc9158b-1427-4b88-e76f-b063441c180b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "!python download_model.py 117M"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rFetching checkpoint:   0%|                                              | 0.00/77.0 [00:00<?, ?it/s]\rFetching checkpoint: 1.00kit [00:00, 944kit/s]                                                      \n",
            "\rFetching encoder.json:   0%|                                           | 0.00/1.04M [00:00<?, ?it/s]\rFetching encoder.json: 1.04Mit [00:00, 57.0Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 1.20Mit/s]                                                   \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:06, 74.1Mit/s]                                  \n",
            "Fetching model.ckpt.index: 6.00kit [00:00, 4.93Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 472kit [00:00, 50.8Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 50.5Mit/s]                                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9946gJ007ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('checkpoint'):\n",
        "  os.makedirs(\"checkpoint\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXTOFLMQ1Fzo",
        "colab_type": "code",
        "outputId": "9657534f-23b3-4a70-92c0-a15b71a27a0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd checkpoint"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/toxic-joke-generator/checkpoint\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG-saFOy1OJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('run1'):\n",
        "  os.makedirs(\"run1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dKa_Vx92B6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for f in fl:\n",
        "  if f['title'] == model_folder_name:\n",
        "    for part in f[\"list\"]:\n",
        "      fil = drive.CreateFile({'id':part['id']})\n",
        "      fil.GetContentFile(part['title'][18:])\n",
        "      os.rename(part['title'][18:], \"./run1/\"+part['title'][18:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT0oJYLd5Oxy",
        "colab_type": "code",
        "outputId": "4a1b8b18-45d5-468c-a93f-13e477b9eaec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd .."
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/toxic-joke-generator\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azu6KCOHbhIy",
        "colab_type": "code",
        "outputId": "46e71265-026f-435e-9ca9-933b3ecdc0b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fire>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.1.3)\n",
            "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (2017.4.5)\n",
            "Requirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.21.0)\n",
            "Requirement already satisfied: tqdm==4.31.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (4.31.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2019.3.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbBJ6JoufBGQ",
        "colab_type": "code",
        "outputId": "c445a765-1929-46f0-c840-2dbf8265ebfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3215
        }
      },
      "source": [
        "!python ./train.py --dataset jokes_400_2_3.0_1.txt.npz --batch_size 2 --sample_every 100 --save_every 1000 \\\n",
        "--model_folder_name $model_folder_name --past_model_folder_name $past_folder_name"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/utils/traitlets.py:5: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
            "  warn(\"IPython.utils.traitlets has moved to a top-level traitlets package.\")\n",
            "Get folder list from google drive\n",
            "2019-06-04 01:09:18.420053: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-06-04 01:09:18.420266: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x750c680 executing computations on platform Host. Devices:\n",
            "2019-06-04 01:09:18.420296: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-06-04 01:09:18.585443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-06-04 01:09:18.585924: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x777b760 executing computations on platform CUDA. Devices:\n",
            "2019-06-04 01:09:18.585950: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-06-04 01:09:18.586296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 14.73GiB freeMemory: 14.60GiB\n",
            "2019-06-04 01:09:18.586320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-06-04 01:09:19.022057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-06-04 01:09:19.022121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-06-04 01:09:19.022134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-06-04 01:09:19.022412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /content/toxic-joke-generator/sample.py:51: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /content/toxic-joke-generator/sample.py:53: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.random.categorical instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "2019-06-04 01:09:31.811711: W tensorflow/core/framework/allocator.cc:124] Allocation of 154389504 exceeds 10% of system memory.\n",
            "2019-06-04 01:09:32.369526: W tensorflow/core/framework/allocator.cc:124] Allocation of 154389504 exceeds 10% of system memory.\n",
            "2019-06-04 01:09:32.433538: W tensorflow/core/framework/allocator.cc:124] Allocation of 154389504 exceeds 10% of system memory.\n",
            "2019-06-04 01:09:32.525684: W tensorflow/core/framework/allocator.cc:124] Allocation of 154389504 exceeds 10% of system memory.\n",
            "2019-06-04 01:09:32.799674: W tensorflow/core/framework/allocator.cc:124] Allocation of 154389504 exceeds 10% of system memory.\n",
            "Loading checkpoint models/117M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Loading dataset...\n",
            "100% 1/1 [00:00<00:00,  2.99it/s]\n",
            "dataset has 14022611 tokens\n",
            "Training...\n",
            "2019-06-04 01:09:44.751789: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
            "[1 | 9.97] loss=3.14 avg=3.14\n",
            "[2 | 14.06] loss=3.14 avg=3.14\n",
            "[3 | 18.18] loss=3.05 avg=3.11\n",
            "[4 | 22.30] loss=3.08 avg=3.10\n",
            "[5 | 26.44] loss=2.98 avg=3.08\n",
            "[6 | 30.59] loss=2.95 avg=3.06\n",
            "[7 | 34.76] loss=2.91 avg=3.03\n",
            "[8 | 38.95] loss=2.94 avg=3.02\n",
            "[9 | 43.15] loss=2.88 avg=3.01\n",
            "[10 | 47.38] loss=2.87 avg=2.99\n",
            "[11 | 51.62] loss=2.91 avg=2.98\n",
            "[12 | 55.86] loss=2.87 avg=2.97\n",
            "[13 | 60.13] loss=2.82 avg=2.96\n",
            "[14 | 64.41] loss=2.88 avg=2.96\n",
            "[15 | 68.71] loss=2.86 avg=2.95\n",
            "[16 | 73.03] loss=2.83 avg=2.94\n",
            "[17 | 77.35] loss=2.84 avg=2.93\n",
            "[18 | 81.70] loss=2.81 avg=2.93\n",
            "[19 | 86.06] loss=2.79 avg=2.92\n",
            "[20 | 90.42] loss=2.89 avg=2.92\n",
            "[21 | 94.76] loss=2.78 avg=2.91\n",
            "[22 | 99.11] loss=2.85 avg=2.91\n",
            "[23 | 103.44] loss=2.78 avg=2.90\n",
            "[24 | 107.76] loss=2.87 avg=2.90\n",
            "[25 | 112.07] loss=2.78 avg=2.89\n",
            "[26 | 116.37] loss=2.76 avg=2.89\n",
            "[27 | 120.67] loss=2.79 avg=2.88\n",
            "[28 | 124.97] loss=2.89 avg=2.88\n",
            "[29 | 129.26] loss=2.79 avg=2.88\n",
            "[30 | 133.55] loss=2.81 avg=2.88\n",
            "[31 | 137.83] loss=2.83 avg=2.88\n",
            "[32 | 142.12] loss=2.73 avg=2.87\n",
            "[33 | 146.40] loss=2.76 avg=2.87\n",
            "[34 | 150.69] loss=2.76 avg=2.86\n",
            "[35 | 154.99] loss=2.73 avg=2.86\n",
            "[36 | 159.28] loss=2.73 avg=2.85\n",
            "[37 | 163.59] loss=2.71 avg=2.85\n",
            "[38 | 167.88] loss=2.72 avg=2.85\n",
            "[39 | 172.19] loss=2.73 avg=2.84\n",
            "[40 | 176.49] loss=2.82 avg=2.84\n",
            "[41 | 180.80] loss=2.78 avg=2.84\n",
            "[42 | 185.12] loss=2.77 avg=2.84\n",
            "[43 | 189.43] loss=2.76 avg=2.84\n",
            "[44 | 193.75] loss=2.74 avg=2.83\n",
            "[45 | 198.06] loss=2.83 avg=2.83\n",
            "[46 | 202.37] loss=2.75 avg=2.83\n",
            "[47 | 206.68] loss=2.75 avg=2.83\n",
            "[48 | 210.99] loss=2.73 avg=2.83\n",
            "[49 | 215.29] loss=2.77 avg=2.82\n",
            "[50 | 219.61] loss=2.76 avg=2.82\n",
            "[51 | 223.91] loss=2.74 avg=2.82\n",
            "[52 | 228.21] loss=2.76 avg=2.82\n",
            "[53 | 232.51] loss=2.78 avg=2.82\n",
            "[54 | 236.81] loss=2.76 avg=2.82\n",
            "[55 | 241.13] loss=2.69 avg=2.81\n",
            "[56 | 245.43] loss=2.80 avg=2.81\n",
            "[57 | 249.73] loss=2.77 avg=2.81\n",
            "[58 | 254.03] loss=2.68 avg=2.81\n",
            "[59 | 258.33] loss=2.72 avg=2.81\n",
            "[60 | 262.63] loss=2.77 avg=2.81\n",
            "[61 | 266.93] loss=2.66 avg=2.80\n",
            "[62 | 271.23] loss=2.74 avg=2.80\n",
            "[63 | 275.53] loss=2.76 avg=2.80\n",
            "[64 | 279.83] loss=2.69 avg=2.80\n",
            "[65 | 284.14] loss=2.65 avg=2.80\n",
            "[66 | 288.44] loss=2.76 avg=2.80\n",
            "[67 | 292.74] loss=2.77 avg=2.79\n",
            "[68 | 297.04] loss=2.72 avg=2.79\n",
            "[69 | 301.35] loss=2.74 avg=2.79\n",
            "[70 | 305.65] loss=2.73 avg=2.79\n",
            "[71 | 309.96] loss=2.70 avg=2.79\n",
            "[72 | 314.27] loss=2.69 avg=2.79\n",
            "[73 | 318.57] loss=2.78 avg=2.79\n",
            "[74 | 322.88] loss=2.70 avg=2.79\n",
            "[75 | 327.18] loss=2.74 avg=2.78\n",
            "[76 | 331.49] loss=2.65 avg=2.78\n",
            "[77 | 335.80] loss=2.81 avg=2.78\n",
            "[78 | 340.10] loss=2.71 avg=2.78\n",
            "[79 | 344.40] loss=2.71 avg=2.78\n",
            "[80 | 348.71] loss=2.66 avg=2.78\n",
            "[81 | 353.01] loss=2.72 avg=2.78\n",
            "[82 | 357.32] loss=2.72 avg=2.78\n",
            "[83 | 361.62] loss=2.74 avg=2.78\n",
            "[84 | 365.93] loss=2.66 avg=2.77\n",
            "[85 | 370.23] loss=2.65 avg=2.77\n",
            "[86 | 374.53] loss=2.67 avg=2.77\n",
            "[87 | 378.84] loss=2.71 avg=2.77\n",
            "[88 | 383.14] loss=2.68 avg=2.77\n",
            "[89 | 387.45] loss=2.68 avg=2.77\n",
            "[90 | 391.76] loss=2.68 avg=2.76\n",
            "[91 | 396.07] loss=2.69 avg=2.76\n",
            "[92 | 400.37] loss=2.73 avg=2.76\n",
            "[93 | 404.69] loss=2.66 avg=2.76\n",
            "[94 | 409.00] loss=2.70 avg=2.76\n",
            "[95 | 413.30] loss=2.66 avg=2.76\n",
            "[96 | 417.60] loss=2.66 avg=2.76\n",
            "[97 | 421.90] loss=2.64 avg=2.75\n",
            "[98 | 426.21] loss=2.67 avg=2.75\n",
            "[99 | 430.51] loss=2.69 avg=2.75\n",
            "======== SAMPLE 1 ========\n",
            ".\" So they put a guy in it. Wow that's a good name for a girl. #joke #joke #joke #Joke #Joke #Joke #Joke #WTF#joke\n",
            "\n",
            "I have a boyfriend......I'm writing about him. <|endoftext|>\n",
            "\n",
            "What do you get if a gay couple walks into a bar and the bartender asks \"Where was it?\" A: No... it was a big fat ass on the side. <|endoftext|>\n",
            "\n",
            "How many times can you say \"Merry Christmas\"? Answer 1. You can't. <|endoftext|>\n",
            "\n",
            "Why don't you hear more bad news about a girl? Don't worry, your phone's ringing.. <|endoftext|>\n",
            "\n",
            "What's Hitler's favorite type of beer? He's too-tall. <|endoftext|>\n",
            "\n",
            "How many Muslims does it take to\n",
            "\n",
            "[100 | 437.75] loss=2.66 avg=2.75\n",
            "[101 | 442.05] loss=2.63 avg=2.75\n",
            "[102 | 446.36] loss=2.72 avg=2.75\n",
            "[103 | 450.66] loss=2.61 avg=2.75\n",
            "[104 | 454.97] loss=2.59 avg=2.74\n",
            "[105 | 459.27] loss=2.66 avg=2.74\n",
            "[106 | 463.58] loss=2.66 avg=2.74\n",
            "[107 | 467.88] loss=2.66 avg=2.74\n",
            "[108 | 472.19] loss=2.63 avg=2.74\n",
            "[109 | 476.50] loss=2.70 avg=2.74\n",
            "[110 | 480.81] loss=2.71 avg=2.74\n",
            "[111 | 485.12] loss=2.69 avg=2.74\n",
            "[112 | 489.43] loss=2.66 avg=2.74\n",
            "[113 | 493.74] loss=2.70 avg=2.74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-H4kkl3E34D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r /content/gpt-2/checkpoint/run1/* /content/gpt-2/models/117M/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2csc2bZHfrXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 generate_unconditional_samples.py --top_k 40 --temperature 1.2"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}